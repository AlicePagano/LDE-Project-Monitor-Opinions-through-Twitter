{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:16.990709Z",
     "start_time": "2021-01-06T15:40:16.281853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "# Set keys\n",
    "consumer_key= 'svKJvnLZnXayRm2frd4DduozL'\n",
    "consumer_secret= 'mfdYmky8LVpBUyj5yv1xTGHwc4O4QTIfhh6uo0VBjnHA4AsL5e'\n",
    "access_token= '1331337099786776576-EDuVu6acOiOTGFHn0LsC6wgNPOlNzI'\n",
    "access_token_secret= '8oQ6HJEOiWexEueOlUdT5YBslzvc8qdN3aZP8ZiOssiWS'\n",
    "\n",
    "folder_name = 'arrange_data/'\n",
    "\n",
    "# Access with API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:18.037341Z",
     "start_time": "2021-01-06T15:40:17.012923Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2017 = pd.read_excel(folder_name+'tag_dataset_2017.xlsx',engine='openpyxl',index_col=0,header=[0,1])\n",
    "df_2018 = pd.read_excel(folder_name+'tag_dataset_2018.xlsx',engine='openpyxl',index_col=0,header=[0,1])\n",
    "df_2019 = pd.read_excel(folder_name+'tag_dataset_2019.xlsx',engine='openpyxl',index_col=0,header=[0,1])\n",
    "df_2020 = pd.read_excel(folder_name+'tag_dataset_2020.xlsx',engine='openpyxl',index_col=0,header=[0,1])\n",
    "\n",
    "#data = pd.concat([df_2017,df_2018,df_2019,df_2020],ignore_index=True)\n",
    "\n",
    "# Filter only for novax people\n",
    "#data = data[data[('user','tag')]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:27:58.081464Z",
     "start_time": "2021-01-06T15:27:58.062764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_2017],ignore_index=True)\n",
    "data = data[data[('user','tag')]==1]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:27:59.485632Z",
     "start_time": "2021-01-06T15:27:59.478090Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N batch: 8\n",
      "List size: 8\n"
     ]
    }
   ],
   "source": [
    "tweet_id = np.array(data[(\"tweet\",\"id\")])\n",
    "\n",
    "batch_size = 50\n",
    "N_batch = int( np.ceil(tweet_id.shape[0]/batch_size) )\n",
    "\n",
    "print('N batch:',N_batch)\n",
    "\n",
    "tweet_id_list = []\n",
    "\n",
    "for k in range(N_batch):\n",
    "    l = k*batch_size\n",
    "    u = min((k+1)*batch_size, tweet_id.shape[0])\n",
    "    tweet_id_list.append(tweet_id[l:u])\n",
    "    \n",
    "print('List size:', len(tweet_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:09.483721Z",
     "start_time": "2021-01-06T15:28:01.136345Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for 50size batch: 35\n",
      "Size for 50size batch: 35\n",
      "Size for 50size batch: 32\n",
      "Size for 50size batch: 28\n",
      "Size for 50size batch: 32\n",
      "Size for 50size batch: 38\n",
      "Size for 50size batch: 29\n",
      "Size for 50size batch: 8\n",
      "Final data shape: (237, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert relevant informations to a Pandas dataframe\n",
    "columns = [[\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\n",
    "         \"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\"],\n",
    "         [\"screen_name\", \"id\", \"description\", \"location\", \"followers_count\", \"favourites_count\", \"created_at\",\n",
    "          \"id\", \"created_at\", \"text\",\"favorites_count\",\"retweet_count\",\"in_reply_to_screen_name\",\"entities\"]]\n",
    "\n",
    "tweet_data_list = []\n",
    "\n",
    "for IDs in tweet_id_list:\n",
    "    \n",
    "    IDs = list(IDs)\n",
    "    tweets = api.statuses_lookup(IDs)\n",
    "    \n",
    "    print('Size for '+str(batch_size)+' size batch:',len(tweets))\n",
    "    \n",
    "    # Store relevant informations\n",
    "    tweets_info = [[tweet.user.screen_name, tweet.user.id, tweet.user.description, tweet.user.location, \n",
    "                 tweet.user.followers_count, tweet.user.favourites_count, tweet.user.created_at, \n",
    "                tweet.id, tweet.created_at, tweet.text, tweet.favorite_count, \n",
    "                tweet.retweet_count, tweet.in_reply_to_screen_name,tweet.entities] for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(data=tweets_info,columns=columns)\n",
    "    \n",
    "    tweet_data_list.append(df)\n",
    "\n",
    "tweet_data = pd.concat(tweet_data_list,ignore_index=True)\n",
    "print('Final data shape:', tweet_data.shape)\n",
    "\n",
    "# Convert to a file excel\n",
    "tweet_data.to_excel(folder_name+'new_dataset_2017.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:26:22.902890Z",
     "start_time": "2021-01-06T15:26:22.899502Z"
    }
   },
   "outputs": [],
   "source": [
    "#tweet[0].entities.get('hashtags')[0].get('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:12.962168Z",
     "start_time": "2021-01-06T15:28:12.952176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_2018],ignore_index=True)\n",
    "data = data[data[('user','tag')]==1]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:16.388767Z",
     "start_time": "2021-01-06T15:28:16.384528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N batch: 8\n",
      "List size: 8\n"
     ]
    }
   ],
   "source": [
    "tweet_id = np.array(data[(\"tweet\",\"id\")])\n",
    "\n",
    "batch_size = 50\n",
    "N_batch = int( np.ceil(tweet_id.shape[0]/batch_size) )\n",
    "\n",
    "print('N batch:',N_batch)\n",
    "\n",
    "tweet_id_list = []\n",
    "\n",
    "for k in range(N_batch):\n",
    "    l = k*batch_size\n",
    "    u = min((k+1)*batch_size, tweet_id.shape[0])\n",
    "    tweet_id_list.append(tweet_id[l:u])\n",
    "    \n",
    "print('List size:', len(tweet_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:25.119019Z",
     "start_time": "2021-01-06T15:28:19.651256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for 50 size batch: 32\n",
      "Size for 50 size batch: 34\n",
      "Size for 50 size batch: 11\n",
      "Size for 50 size batch: 3\n",
      "Size for 50 size batch: 3\n",
      "Size for 50 size batch: 17\n",
      "Size for 50 size batch: 3\n",
      "Size for 50 size batch: 1\n",
      "Final data shape: (104, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert relevant informations to a Pandas dataframe\n",
    "columns = [[\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\n",
    "         \"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\"],\n",
    "         [\"screen_name\", \"id\", \"description\", \"location\", \"followers_count\", \"favourites_count\", \"created_at\",\n",
    "          \"id\", \"created_at\", \"text\",\"favorites_count\",\"retweet_count\",\"in_reply_to_screen_name\",\"entities\"]]\n",
    "\n",
    "tweet_data_list = []\n",
    "\n",
    "for IDs in tweet_id_list:\n",
    "    \n",
    "    IDs = list(IDs)\n",
    "    tweets = api.statuses_lookup(IDs)\n",
    "    \n",
    "    print('Size for '+str(batch_size)+' size batch:',len(tweets))\n",
    "    \n",
    "    # Store relevant informations\n",
    "    tweets_info = [[tweet.user.screen_name, tweet.user.id, tweet.user.description, tweet.user.location, \n",
    "                 tweet.user.followers_count, tweet.user.favourites_count, tweet.user.created_at, \n",
    "                tweet.id, tweet.created_at, tweet.text, tweet.favorite_count, \n",
    "                tweet.retweet_count, tweet.in_reply_to_screen_name,tweet.entities] for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(data=tweets_info,columns=columns)\n",
    "    \n",
    "    tweet_data_list.append(df)\n",
    "\n",
    "tweet_data = pd.concat(tweet_data_list,ignore_index=True)\n",
    "print('Final data shape:', tweet_data.shape)\n",
    "\n",
    "# Convert to a file excel\n",
    "tweet_data.to_excel(folder_name+'new_dataset_2018.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:27.359190Z",
     "start_time": "2021-01-06T15:28:27.347516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_2019],ignore_index=True)\n",
    "data = data[data[('user','tag')]==1]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:29.456463Z",
     "start_time": "2021-01-06T15:28:29.450498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N batch: 8\n",
      "List size: 8\n"
     ]
    }
   ],
   "source": [
    "tweet_id = np.array(data[(\"tweet\",\"id\")])\n",
    "\n",
    "batch_size = 50\n",
    "N_batch = int( np.ceil(tweet_id.shape[0]/batch_size) )\n",
    "\n",
    "print('N batch:',N_batch)\n",
    "\n",
    "tweet_id_list = []\n",
    "\n",
    "for k in range(N_batch):\n",
    "    l = k*batch_size\n",
    "    u = min((k+1)*batch_size, tweet_id.shape[0])\n",
    "    tweet_id_list.append(tweet_id[l:u])\n",
    "    \n",
    "print('List size:', len(tweet_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:28:36.334126Z",
     "start_time": "2021-01-06T15:28:31.435640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for 50 size batch: 5\n",
      "Size for 50 size batch: 9\n",
      "Size for 50 size batch: 4\n",
      "Size for 50 size batch: 7\n",
      "Size for 50 size batch: 10\n",
      "Size for 50 size batch: 3\n",
      "Size for 50 size batch: 8\n",
      "Size for 50 size batch: 1\n",
      "Final data shape: (47, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert relevant informations to a Pandas dataframe\n",
    "columns = [[\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\n",
    "         \"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\"],\n",
    "         [\"screen_name\", \"id\", \"description\", \"location\", \"followers_count\", \"favourites_count\", \"created_at\",\n",
    "          \"id\", \"created_at\", \"text\",\"favorites_count\",\"retweet_count\",\"in_reply_to_screen_name\",\"entities\"]]\n",
    "\n",
    "tweet_data_list = []\n",
    "\n",
    "for IDs in tweet_id_list:\n",
    "    \n",
    "    IDs = list(IDs) \n",
    "    tweets = api.statuses_lookup(IDs)\n",
    "    \n",
    "    print('Size for '+str(batch_size)+' size batch:',len(tweets))\n",
    "    \n",
    "    # Store relevant informations\n",
    "    tweets_info = [[tweet.user.screen_name, tweet.user.id, tweet.user.description, tweet.user.location, \n",
    "                 tweet.user.followers_count, tweet.user.favourites_count, tweet.user.created_at, \n",
    "                tweet.id, tweet.created_at, tweet.text, tweet.favorite_count, \n",
    "                tweet.retweet_count, tweet.in_reply_to_screen_name,tweet.entities] for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(data=tweets_info,columns=columns)\n",
    "    \n",
    "    tweet_data_list.append(df)\n",
    "\n",
    "tweet_data = pd.concat(tweet_data_list,ignore_index=True)\n",
    "print('Final data shape:', tweet_data.shape)\n",
    "\n",
    "# Convert to a file excel\n",
    "tweet_data.to_excel(folder_name+'new_dataset_2019.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:20.951209Z",
     "start_time": "2021-01-06T15:40:20.931734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_2020],ignore_index=True)\n",
    "data = data[data[('user','tag')]==1]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:22.541057Z",
     "start_time": "2021-01-06T15:40:22.532739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N batch: 5\n",
      "List size: 5\n"
     ]
    }
   ],
   "source": [
    "tweet_id = np.array(data[(\"tweet\",\"id\")])\n",
    "\n",
    "batch_size = 50\n",
    "N_batch = int( np.ceil(tweet_id.shape[0]/batch_size) )\n",
    "\n",
    "print('N batch:',N_batch)\n",
    "\n",
    "tweet_id_list = []\n",
    "\n",
    "for k in range(N_batch):\n",
    "    l = k*batch_size\n",
    "    u = min((k+1)*batch_size, tweet_id.shape[0])\n",
    "    tweet_id_list.append(tweet_id[l:u])\n",
    "    \n",
    "print('List size:', len(tweet_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:28.775084Z",
     "start_time": "2021-01-06T15:40:25.466605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for 50 size batch: 6\n",
      "Size for 50 size batch: 5\n",
      "Size for 50 size batch: 6\n",
      "Size for 50 size batch: 4\n",
      "Size for 50 size batch: 7\n",
      "Final data shape: (28, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert relevant informations to a Pandas dataframe\n",
    "columns = [[\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\"user\",\n",
    "         \"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\",\"tweet\"],\n",
    "         [\"screen_name\", \"id\", \"description\", \"location\", \"followers_count\", \"favourites_count\", \"created_at\",\n",
    "          \"id\", \"created_at\", \"text\",\"favorites_count\",\"retweet_count\",\"in_reply_to_screen_name\",\"entities\"]]\n",
    "\n",
    "tweet_data_list = []\n",
    "\n",
    "for IDs in tweet_id_list:\n",
    "    \n",
    "    IDs = list(IDs)\n",
    "    tweets = api.statuses_lookup(IDs)\n",
    "    \n",
    "    print('Size for '+str(batch_size)+' size batch:',len(tweets))\n",
    "    \n",
    "    # Store relevant informations\n",
    "    tweets_info = [[tweet.user.screen_name, tweet.user.id, tweet.user.description, tweet.user.location, \n",
    "                 tweet.user.followers_count, tweet.user.favourites_count, tweet.user.created_at, \n",
    "                tweet.id, tweet.created_at, tweet.text, tweet.favorite_count, \n",
    "                tweet.retweet_count, tweet.in_reply_to_screen_name,tweet.entities] for tweet in tweets]\n",
    "\n",
    "    df = pd.DataFrame(data=tweets_info,columns=columns)\n",
    "    \n",
    "    tweet_data_list.append(df)\n",
    "\n",
    "tweet_data = pd.concat(tweet_data_list,ignore_index=True)\n",
    "print('Final data shape:', tweet_data.shape)\n",
    "\n",
    "# Convert to a file excel\n",
    "tweet_data.to_excel(folder_name+'new_dataset_2020.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:40:32.901576Z",
     "start_time": "2021-01-06T15:40:32.894378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1223301908783301120, 1223229885235200000, 1223221289411890944,\n",
       "       1223175880605827072, 1220828033847889920, 1220462829972730112,\n",
       "       1220424480092312064, 1220279979277192960, 1220277162592423936,\n",
       "       1220273423198408960, 1220118201780130048, 1220092878946471936,\n",
       "       1220083907879756032, 1219970390296079872, 1219908758932946944,\n",
       "       1219870808803302912, 1219581300081922048, 1233767903863934976,\n",
       "       1232988008099569920, 1232810513861677056, 1232607123185504000,\n",
       "       1232560895802428928, 1232554750639582976, 1232487991886500096,\n",
       "       1232436266433536000, 1232429638665867008, 1232425075162406912,\n",
       "       1232424822686277888, 1232416610528453120, 1229648630740652032,\n",
       "       1229525558947667968, 1229262770719292928, 1242155967611121920,\n",
       "       1235937135745797888, 1255166739639386112, 1255023026468531968,\n",
       "       1254590680401433088, 1254522707519119104, 1254433242222125056,\n",
       "       1254062983875043072, 1253791854275046912, 1253780072164622080,\n",
       "       1253661470866498048, 1253600247571525888, 1253477210020811008,\n",
       "       1253452063104732928, 1253425487512101120, 1253379651566779904,\n",
       "       1253250686655004928, 1253250636046630912])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_id_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:42:50.924672Z",
     "start_time": "2021-01-06T15:42:50.526336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = api.statuses_lookup([1223301908783301120])\n",
    "\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T15:30:28.204392Z",
     "start_time": "2021-01-06T15:30:28.175596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">user</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tweet</th>\n",
       "      <th colspan=\"9\" halign=\"left\">user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>code_region</th>\n",
       "      <th>region</th>\n",
       "      <th>lat_region</th>\n",
       "      <th>lon_region</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>lat_province</th>\n",
       "      <th>lon_province</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ariannar1978</td>\n",
       "      <td>766246807697514496</td>\n",
       "      <td>💖💖 A day without laughter is a day wasted.💖💖 T...</td>\n",
       "      <td>veneto  italy</td>\n",
       "      <td>619</td>\n",
       "      <td>33481</td>\n",
       "      <td>2016-08-18 12:14:10</td>\n",
       "      <td>1219581300081922048</td>\n",
       "      <td>2020-01-21 11:23:34.999999</td>\n",
       "      <td>L'OMS sulla sicurezza vaccinale https://t.co/w...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>veneto</td>\n",
       "      <td>45.437191</td>\n",
       "      <td>12.33459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                      \\\n",
       "     screen_name                  id   \n",
       "16  Ariannar1978  766246807697514496   \n",
       "\n",
       "                                                                      \\\n",
       "                                          description       location   \n",
       "16  💖💖 A day without laughter is a day wasted.💖💖 T...  veneto  italy   \n",
       "\n",
       "                                                                       tweet  \\\n",
       "   followers_count favourites_count          created_at                   id   \n",
       "16             619            33481 2016-08-18 12:14:10  1219581300081922048   \n",
       "\n",
       "                               \\\n",
       "                   created_at   \n",
       "16 2020-01-21 11:23:34.999999   \n",
       "\n",
       "                                                       ...                \\\n",
       "                                                 text  ... retweet_count   \n",
       "16  L'OMS sulla sicurezza vaccinale https://t.co/w...  ...             0   \n",
       "\n",
       "          user                                                           \\\n",
       "   code_region  region lat_region lon_region city province lat_province   \n",
       "16           5  veneto  45.437191   12.33459  NaN      NaN          NaN   \n",
       "\n",
       "                     \n",
       "   lon_province tag  \n",
       "16          NaN   1  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data[('tweet','id')]==1219581300081922048]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
